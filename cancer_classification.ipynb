{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9e3e4-b485-468f-bd97-446edea26a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_data(train_path, test_path):\n",
    "    # 데이터 로드\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    # ID 열 제거\n",
    "    train_df = train_df.set_index('ID')\n",
    "    test_df = test_df.set_index('ID')\n",
    "    \n",
    "    # train 데이터에서 SUBCLASS 열 분리\n",
    "    train_subclass = train_df['SUBCLASS']\n",
    "    train_df = train_df.drop('SUBCLASS', axis=1)\n",
    "    \n",
    "    # 결측치를 WT로 채우기\n",
    "    train_df = train_df.fillna('WT')\n",
    "    test_df = test_df.fillna('WT')\n",
    "    \n",
    "    return train_df, test_df, train_subclass\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "train_df, test_df, train_subclass = load_and_preprocess_data('/kaggle/input/datadata/train.csv', '/kaggle/input/datadata/test.csv')\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"Train SUBCLASS shape:\", train_subclass.shape)\n",
    "\n",
    "# 처음 5개 행과 5개 열 출력\n",
    "print(\"\\nTrain data preview:\")\n",
    "print(train_df.iloc[:5, :5])\n",
    "print(\"\\nTest data preview:\")\n",
    "print(test_df.iloc[:5, :5])\n",
    "print(\"\\nTrain SUBCLASS preview:\")\n",
    "print(train_subclass.head())\n",
    "\n",
    "# SUBCLASS의 유니크 값 확인\n",
    "print(\"\\nUnique SUBCLASS values:\")\n",
    "print(train_subclass.unique())\n",
    "\n",
    "# 각 SUBCLASS의 개수 확인\n",
    "print(\"\\nSUBCLASS value counts:\")\n",
    "print(train_subclass.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8f763-2593-40bb-b65e-16138e9572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "대회에서 주어진 test , train 데이터를 로드하고 subclass는 타겟변수이기 때문에 정보누출을 막기위해서 따로 분리하여 저장하고 결측치는 wt로 저장하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17290c72-dc56-4ef0-a3c2-7e2b99878605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 변이 유형을 순서에 따라 정의 (우선순위가 높은 변이일수록 먼저 처리)\n",
    "# 1: WT, 2: Multiple Mutations, 3: Synonymous, 4: Nonsynonymous, 5: Nonsense, 6: Frameshift\n",
    "mutation_types = {\n",
    "    'WT': 0,\n",
    "    'Multiple Mutations': 1,\n",
    "    'Synonymous': 2,\n",
    "    'Nonsynonymous': 3,\n",
    "    'Nonsense': 4,\n",
    "    'Frameshift': 5\n",
    "}\n",
    "\n",
    "# 변이 유형을 판별하는 함수들 정의\n",
    "def is_synonymous(mutation):\n",
    "    return mutation != 'WT' and len(mutation) > 1 and mutation[0] == mutation[-1]\n",
    "\n",
    "def is_nonsynonymous(mutation):\n",
    "    return mutation != 'WT' and not is_synonymous(mutation) and '*' not in mutation and 'fs' not in mutation\n",
    "\n",
    "def is_nonsense(mutation):\n",
    "    return '*' in mutation\n",
    "\n",
    "def is_frameshift(mutation):\n",
    "    return 'fs' in mutation\n",
    "\n",
    "def is_multiple_mutations(mutation):\n",
    "    return ' ' in mutation  # 공백이 있는 경우 여러 변이가 발생한 경우로 처리\n",
    "\n",
    "def is_wt(mutation):\n",
    "    return mutation == 'WT'\n",
    "\n",
    "# 레이블 인코딩 함수 정의 (다중 변이 우선 처리)\n",
    "def label_encode_mutations(mutation_string):\n",
    "    # 다중 변이 여부 확인\n",
    "    if is_multiple_mutations(mutation_string):\n",
    "        return mutation_types['Multiple Mutations']  # Multiple Mutations 인코딩\n",
    "    \n",
    "    # 다중 변이가 아닌 경우, 단일 변이 타입을 우선순위에 따라 처리\n",
    "    if is_wt(mutation_string):\n",
    "        return mutation_types['WT']\n",
    "    elif is_synonymous(mutation_string):\n",
    "        return mutation_types['Synonymous']\n",
    "    elif is_nonsynonymous(mutation_string):\n",
    "        return mutation_types['Nonsynonymous']\n",
    "    elif is_nonsense(mutation_string):\n",
    "        return mutation_types['Nonsense']\n",
    "    elif is_frameshift(mutation_string):\n",
    "        return mutation_types['Frameshift']\n",
    "\n",
    "# 각 셀에서 변이 정보를 하나씩 인코딩하여 개별적으로 변환하는 함수\n",
    "def encode_cell(mutation_string):\n",
    "    return label_encode_mutations(mutation_string)\n",
    "\n",
    "# 라벨 인코딩 수행 함수 수정\n",
    "def label_encode_dataframe(df):\n",
    "    # 각 열에 대해 인코딩 함수 적용\n",
    "    encoded_df = df.apply(lambda col: col.map(encode_cell))\n",
    "    return encoded_df\n",
    "    \n",
    "\n",
    "# 라벨 인코딩된 뷰 생성\n",
    "train_encoded_view = label_encode_dataframe(train_df)\n",
    "test_encoded_view = label_encode_dataframe(test_df)\n",
    "\n",
    "# 인코딩된 데이터 확인\n",
    "print(\"\\nEncoded Train View preview:\")\n",
    "print(train_encoded_view.head())\n",
    "\n",
    "print(\"\\nEncoded Test View preview:\")\n",
    "print(test_encoded_view.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0efdf-090a-4b68-adb1-3315b551f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "유전자변이 타입에 따라 라벨 인코딩(view 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716291f6-84f5-46de-8a55-a1904904e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_binary_mutation_view(df):\n",
    "    # 변이 유형을 순서에 따라 정의\n",
    "    mutation_types = ['WT', 'Multiple Mutations', 'Synonymous', 'Nonsynonymous', 'Nonsense', 'Frameshift']\n",
    "\n",
    "    # 변이 유형을 판별하는 함수들 정의\n",
    "    def get_mutation_type(mutation):\n",
    "        if pd.isna(mutation) or mutation == 'WT':\n",
    "            return 'WT'\n",
    "        if ' ' in mutation:\n",
    "            return 'Multiple Mutations'\n",
    "        if '*' in mutation:\n",
    "            return 'Nonsense'\n",
    "        if 'fs' in mutation:\n",
    "            return 'Frameshift'\n",
    "        if len(mutation) > 1 and mutation[0] == mutation[-1]:\n",
    "            return 'Synonymous'\n",
    "        return 'Nonsynonymous'\n",
    "\n",
    "    # 변이 유형별 열 생성\n",
    "    binary_data = {}\n",
    "    for gene in df.columns:\n",
    "        for m_type in mutation_types:\n",
    "            col_name = f\"{gene}_{m_type}\"\n",
    "            binary_data[col_name] = []\n",
    "\n",
    "    # 각 셀을 순회하며 해당하는 열에 1을 설정\n",
    "    for idx, row in df.iterrows():\n",
    "        for gene in df.columns:\n",
    "            mutation_type = get_mutation_type(row[gene])\n",
    "            for m_type in mutation_types:\n",
    "                col_name = f\"{gene}_{m_type}\"\n",
    "                if mutation_type == m_type:\n",
    "                    binary_data[col_name].append(1)\n",
    "                else:\n",
    "                    binary_data[col_name].append(0)\n",
    "\n",
    "    # 새로운 이진 변이 데이터프레임 생성\n",
    "    binary_df = pd.DataFrame(binary_data, index=df.index)\n",
    "\n",
    "    return binary_df\n",
    "\n",
    "# ===========================================\n",
    "# 기존에 정의된 train_df와 test_df 사용\n",
    "# ===========================================\n",
    "\n",
    "# 이진 변이 뷰 생성\n",
    "train_binary_mutation_view = create_binary_mutation_view(train_df)\n",
    "test_binary_mutation_view = create_binary_mutation_view(test_df)\n",
    "\n",
    "print(\"\\nTrain Binary Mutation View:\")\n",
    "print(train_binary_mutation_view.head())\n",
    "\n",
    "print(\"\\nTest Binary Mutation View:\")\n",
    "print(test_binary_mutation_view.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09694c67-c36f-4d8d-bc8f-0bd25143cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "라벨데이터를 원핫인코딩하여 새롭게 저장(view 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a64172-4ce2-4cf3-91e2-46b9205bc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_positions(mutation_string):\n",
    "    \"\"\"돌연변이 문자열에서 위치 정보를 추출\"\"\"\n",
    "    if pd.isna(mutation_string) or mutation_string == 'WT':\n",
    "        return []\n",
    "    return [int(pos) for pos in re.findall(r'[A-Z](\\d+)[A-Z*]', mutation_string)]\n",
    "\n",
    "def find_max_position(df):\n",
    "    \"\"\"데이터프레임에서 최대 돌연변이 위치를 찾는 함수\"\"\"\n",
    "    all_positions = df.apply(lambda col: [pos for mutation in col for pos in extract_positions(mutation)])\n",
    "    max_position = max([max(positions, default=0) for positions in all_positions], default=0)\n",
    "    return max_position\n",
    "\n",
    "def create_mutation_statistics_view(df, max_position):\n",
    "    \"\"\"돌연변이 통계 정보를 계산하여 뷰를 생성하는 함수\"\"\"\n",
    "    def process_column(column):\n",
    "        positions_list = column.apply(extract_positions)\n",
    "        lengths = positions_list.apply(len)\n",
    "\n",
    "        # Non-empty positions 처리\n",
    "        non_empty_mask = lengths > 0\n",
    "        non_empty_positions = positions_list[non_empty_mask]\n",
    "        \n",
    "        stats = {\n",
    "            'count': lengths,\n",
    "            'mean': np.zeros_like(lengths, dtype=float),\n",
    "            'std': np.zeros_like(lengths, dtype=float),\n",
    "            'min': np.zeros_like(lengths, dtype=float),\n",
    "            'max': np.zeros_like(lengths, dtype=float),\n",
    "            'range': np.zeros_like(lengths, dtype=float)\n",
    "        }\n",
    "        \n",
    "        if non_empty_positions.any():\n",
    "            flattened_positions = non_empty_positions.apply(np.array)\n",
    "            stats['mean'][non_empty_mask] = flattened_positions.apply(np.mean)\n",
    "            stats['std'][non_empty_mask] = flattened_positions.apply(lambda pos: np.std(pos) if len(pos) > 1 else 0)\n",
    "            stats['min'][non_empty_mask] = flattened_positions.apply(np.min)\n",
    "            stats['max'][non_empty_mask] = flattened_positions.apply(np.max)\n",
    "            stats['range'][non_empty_mask] = stats['max'][non_empty_mask] - stats['min'][non_empty_mask]\n",
    "        \n",
    "        return pd.DataFrame(stats)\n",
    "\n",
    "    # 각 컬럼에 대해 통계 계산 후 합치기\n",
    "    result = pd.concat({col: process_column(df[col]) for col in df.columns}, axis=1)\n",
    "    \n",
    "    # 다중 인덱스를 플랫(flat)하게 변환\n",
    "    result.columns = [f'{col[0]}_{col[1]}' for col in result.columns]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 메인 코드\n",
    "max_position_train = find_max_position(train_df)\n",
    "max_position_test = find_max_position(test_df)\n",
    "MAX_POSITION = max(max_position_train, max_position_test)\n",
    "MAX_POSITION = ((MAX_POSITION // 1000) + 1) * 1000\n",
    "\n",
    "print(f\"Calculated MAX_POSITION: {MAX_POSITION}\")\n",
    "\n",
    "train_position_stats_view = create_mutation_statistics_view(train_df, MAX_POSITION)\n",
    "test_position_stats_view = create_mutation_statistics_view(test_df, MAX_POSITION)\n",
    "\n",
    "print(\"Train Position Statistics view shape:\", train_position_stats_view.shape)\n",
    "print(\"Test Position Statistics view shape:\", test_position_stats_view.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070023f-54ff-4b80-9543-550bc81b8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "변이된 유전자의 위치를 표현하기 위해서 position_stats_view를 생성 (view 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8035e-a2b0-44f1-9440-9a2b217b599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. 데이터 로딩 및 인덱스 설정\n",
    "# -----------------------------------\n",
    "\n",
    "census_df = pd.read_csv('/kaggle/input/datadata/Census_allThu.csv')\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. 역할 분류 함수 정의\n",
    "# -----------------------------------\n",
    "\n",
    "def classify_role(role):\n",
    "    \"\"\"\n",
    "    주어진 역할 문자열을 분류하여 표준화된 역할을 반환합니다.\n",
    "    \"\"\"\n",
    "    if pd.isna(role):\n",
    "        return 'unknown'\n",
    "    role_lower = role.lower()\n",
    "    if 'tsg' in role_lower and 'fusion' in role_lower:\n",
    "        return 'tsg_fusion'\n",
    "    if 'oncogene' in role_lower and 'fusion' in role_lower:\n",
    "        return 'oncogene_fusion'\n",
    "    if 'tsg' in role_lower:\n",
    "        return 'tsg'\n",
    "    if 'oncogene' in role_lower:\n",
    "        return 'oncogene'\n",
    "    if 'fusion' in role_lower:\n",
    "        return 'fusion'\n",
    "    return 'other'\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. 유전자 정보 처리 및 Role_Label 매핑\n",
    "# -----------------------------------\n",
    "\n",
    "# 유전자 정보를 'Gene Symbol'을 인덱스로 설정하여 저장\n",
    "gene_info = census_df.set_index('Gene Symbol')\n",
    "\n",
    "# 역할 분류 함수 적용\n",
    "gene_info['Classified_Role'] = gene_info['Role in Cancer'].apply(classify_role)\n",
    "\n",
    "# 역할별 Role_Label 매핑 정의\n",
    "# 'unknown'은 0, 'tsg_fusion'은 1, 'oncogene_fusion'은 2, 'tsg'는 3, 'oncogene'은 4, 'fusion'과 'other'는 5로 설정\n",
    "role_mapping = {\n",
    "    'unknown': 0,\n",
    "    'tsg_fusion': 1,\n",
    "    'oncogene_fusion': 2,\n",
    "    'tsg': 3,\n",
    "    'oncogene': 4,\n",
    "    'fusion': 5,\n",
    "    'other': 0\n",
    "}\n",
    "\n",
    "# 'Role_Label' 열 생성\n",
    "gene_info['Role_Label'] = gene_info['Classified_Role'].map(role_mapping)\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. gene_info 확장: train 및 test의 모든 유전자 포함\n",
    "# -----------------------------------\n",
    "\n",
    "# train_df와 test_df의 모든 유전자 목록 결합\n",
    "all_genes = train_df.columns.union(test_df.columns)\n",
    "\n",
    "# gene_info를 all_genes에 맞게 재인덱싱, 없는 유전자는 NaN으로 채움\n",
    "gene_info = gene_info.reindex(all_genes, fill_value=np.nan)\n",
    "\n",
    "# 'Classified_Role'이 NaN인 유전자는 'unknown'으로 채움\n",
    "gene_info['Classified_Role'] = gene_info['Classified_Role'].fillna('unknown')\n",
    "\n",
    "# 'Role_Label'이 NaN인 유전자는 'unknown'의 라벨로 채움 (0)\n",
    "gene_info['Role_Label'] = gene_info['Role_Label'].fillna(role_mapping['unknown']).astype(int)\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. 통합 뷰 생성 함수 정의\n",
    "# -----------------------------------\n",
    "\n",
    "def create_integrated_view(df, gene_info):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 gene_info를 사용하여 통합 뷰를 생성합니다.\n",
    "    유전자가 'WT'가 아닌 경우 해당 유전자의 Role_Label을, 'WT'인 경우 0으로 설정합니다.\n",
    "    \"\"\"\n",
    "    # 데이터프레임 복사\n",
    "    integrated_view = df.copy()\n",
    "    \n",
    "    # 각 유전자에 대해 처리\n",
    "    for gene in df.columns:\n",
    "        role_label = gene_info.loc[gene, 'Role_Label']\n",
    "        # 'WT'가 아닌 경우 role_label, 'WT'인 경우 0으로 설정\n",
    "        # 'WT'는 문자열로 처리되므로, 데이터 타입이 일치하도록 변환\n",
    "        integrated_view[gene] = np.where(integrated_view[gene].astype(str) != 'WT', role_label, 0)\n",
    "    \n",
    "    return integrated_view\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. 통합 뷰 생성\n",
    "# -----------------------------------\n",
    "\n",
    "train_integrated_view = create_integrated_view(train_df, gene_info)\n",
    "test_integrated_view = create_integrated_view(test_df, gene_info)\n",
    "\n",
    "# -----------------------------------\n",
    "# 7. 결과 출력 함수 정의\n",
    "# -----------------------------------\n",
    "\n",
    "def print_view_sample(view, name):\n",
    "    \"\"\"\n",
    "    통합 뷰의 샘플 데이터를 출력합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{name} Integrated View:\")\n",
    "    print(f\"Shape: {view.shape}\")\n",
    "    print(\"First 5 rows and up to 5 columns:\")\n",
    "    print(view.iloc[:5, :5])\n",
    "\n",
    "# -----------------------------------\n",
    "# 8. 결과 출력\n",
    "# -----------------------------------\n",
    "\n",
    "print_view_sample(train_integrated_view, \"Train\")\n",
    "print_view_sample(test_integrated_view, \"Test\")\n",
    "\n",
    "# -----------------------------------\n",
    "# 9. Role_Label 매핑 정보 출력\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"\\nRole Label Mapping:\")\n",
    "for role, label in role_mapping.items():\n",
    "    print(f\"'{role}': {label}\")\n",
    "\n",
    "# -----------------------------------\n",
    "# 10. 데이터 형태 출력\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"\\nOriginal Data Shapes:\")\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nIntegrated View Shapes:\")\n",
    "print(f\"Train Integrated View: {train_integrated_view.shape}\")\n",
    "print(f\"Test Integrated View: {test_integrated_view.shape}\")\n",
    "# 훈련 데이터에서 0이 아닌 값을 포함하는 열의 수 계산\n",
    "train_columns_non_zero = (train_integrated_view != 0).any().sum()\n",
    "\n",
    "# 테스트 데이터에서 0이 아닌 값을 포함하는 열의 수 계산\n",
    "test_columns_non_zero = (test_integrated_view != 0).any().sum()\n",
    "\n",
    "print(f\"훈련 데이터에서 0이 아닌 값을 포함하는 열의 수: {train_columns_non_zero}\")\n",
    "print(f\"테스트 데이터에서 0이 아닌 값을 포함하는 열의 수: {test_columns_non_zero}\")import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 역할별 Role_Label 매핑\n",
    "role_mapping = {\n",
    "    0: 'unknown',\n",
    "    1: 'tsg_fusion',\n",
    "    2: 'oncogene_fusion',\n",
    "    3: 'tsg',\n",
    "    4: 'oncogene',\n",
    "    5: 'fusion'\n",
    "}\n",
    "\n",
    "def expand_role_columns(df, role_mapping):\n",
    "    \"\"\"\n",
    "    각 유전자에 대해 역할별 열을 생성하고, 해당 역할에 대해 1을 표시하는 이진 표현으로 변환합니다.\n",
    "    \"\"\"\n",
    "    # 모든 열 데이터를 저장할 리스트\n",
    "    all_columns = []\n",
    "\n",
    "    # 각 유전자에 대해 역할별로 열 생성\n",
    "    for gene in df.columns:\n",
    "        for role_label, role_name in role_mapping.items():\n",
    "            # 역할별 열 이름 지정 (예: A2M_tsg_fusion)\n",
    "            column_name = f\"{gene}_{role_name}\"\n",
    "            # 해당 역할에 해당하는 값은 1, 나머지는 0으로 설정\n",
    "            col_data = np.where(df[gene] == role_label, 1, 0)\n",
    "            all_columns.append(pd.Series(col_data, name=column_name))\n",
    "    \n",
    "    # 리스트에 저장된 모든 열을 한 번에 데이터프레임으로 병합\n",
    "    expanded_df = pd.concat(all_columns, axis=1)\n",
    "    \n",
    "    return expanded_df\n",
    "\n",
    "# 기존 통합 뷰를 사용하여 확장된 역할 열 생성 (train과 test에 대해 적용)\n",
    "expanded_train_view = expand_role_columns(train_integrated_view, role_mapping)\n",
    "expanded_test_view = expand_role_columns(test_integrated_view, role_mapping)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로딩\n",
    "census_df = pd.read_csv('/kaggle/input/datadata/Census_allThu.csv')\n",
    "\n",
    "# 1단계: census_df에서 유전자 정보를 인덱스로 설정하고 Hallmark 정보를 이진값으로 변환 (Yes -> 1, No -> 0)\n",
    "gene_info = census_df.set_index('Gene Symbol')\n",
    "gene_info['Hallmark'] = (gene_info['Hallmark'] == 'Yes').astype(int)\n",
    "\n",
    "# Hallmark view 생성 함수\n",
    "def create_hallmark_view(df, gene_info):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임(df)에서 유전자들이 census_df와 일치하는지 확인하여 \n",
    "    일치하는 경우 Hallmark 값을 적용하고, 일치하지 않는 유전자는 0으로 설정합니다.\n",
    "    \"\"\"\n",
    "    hallmark_view = df.copy()  # 원본을 복사해서 사용\n",
    "    for gene in df.columns:\n",
    "        if gene in gene_info.index:\n",
    "            # 해당 유전자가 census_df에 존재하면 해당 유전자의 Hallmark 값을 적용\n",
    "            hallmark_value = gene_info.loc[gene, 'Hallmark']\n",
    "            hallmark_view[gene] = np.where(hallmark_view[gene] != 'WT', hallmark_value, 0)\n",
    "        else:\n",
    "            # 해당 유전자가 census_df에 존재하지 않으면 모든 값을 0으로 설정\n",
    "            hallmark_view[gene] = 0\n",
    "    return hallmark_view\n",
    "\n",
    "# train_df 및 test_df에 대해 Hallmark view 생성\n",
    "train_hallmark_view = create_hallmark_view(train_df, gene_info)\n",
    "test_hallmark_view = create_hallmark_view(test_df, gene_info)\n",
    "\n",
    "# 결과 출력 함수 정의\n",
    "def print_view_sample(view, name):\n",
    "    \"\"\"\n",
    "    뷰의 첫 5행과 첫 5열을 출력하고 첫 번째 열의 값 카운트를 출력합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{name} View:\")\n",
    "    print(f\"Shape: {view.shape}\")\n",
    "    print(\"First 5 rows and up to 5 columns:\")\n",
    "    print(view.iloc[:5, :5])\n",
    "    print(\"\\nValue counts for the first column:\")\n",
    "    print(view.iloc[:, 0].value_counts())\n",
    "\n",
    "# Train 및 Test 데이터의 Hallmark View 샘플 출력\n",
    "print_view_sample(train_hallmark_view, \"Train Hallmark\")\n",
    "print_view_sample(test_hallmark_view, \"Test Hallmark\")\n",
    "\n",
    "# 원본 데이터와 Hallmark view의 shape 출력\n",
    "print(\"\\nOriginal Data Shapes:\")\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nHallmark View Shapes:\")\n",
    "print(f\"Train: {train_hallmark_view.shape}\")\n",
    "print(f\"Test: {test_hallmark_view.shape}\")\n",
    "\n",
    "# Hallmark 정보 출력\n",
    "print(\"\\nHallmark Information:\")\n",
    "print(gene_info['Hallmark'].value_counts())\n",
    "# 훈련 데이터에서 1의 값을 포함하는 열의 수 계산\n",
    "\n",
    "train_columns_with_ones = (train_hallmark_view == 1).any().sum()\n",
    "\n",
    "# 테스트 데이터에서 1의 값을 포함하는 열의 수 계산\n",
    "test_columns_with_ones = (test_hallmark_view == 1).any().sum()\n",
    "\n",
    "print(f\"훈련 데이터에서 1의 값을 포함하는 열의 수: {train_columns_with_ones}\")\n",
    "print(f\"테스트 데이터에서 1의 값을 포함하는 열의 수: {test_columns_with_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6dc081-ea2f-454d-aed4-c91cf9da6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "암에 대한 외부데이터를 이용해서 암에 중요하다고 알려진 유전자를 추출하여 유전자가 암의 Hallmark 특징과 관련이 있는지 여부 ,유전자의 암에서의 역할 (예: 종양 유전자, 종양 억제 유전자, 융합 유전자 등).\n",
    "이에 대해서 3개의 view를 더 정의하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b64498-1435-40f6-b476-56e59ff0445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "위에서 여러가지 view를 정의한 이유는 데이터 증강의 목적과 하나의 데이터로는 암을 분류하기 어렵다고 판단하여\n",
    "데이터를 여러가지 방향으로 살펴보고 여러방향으로 학습시켜 데이터끼리의 미흡점을 보완하기 위해서이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab6f5f-d650-433c-97eb-4b3f578841b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "# ---------------------------\n",
    "# 0. 레이블 인코딩\n",
    "# ---------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(train_subclass)\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Train 데이터 스케일링 및 희소 행렬로 변환\n",
    "# ---------------------------\n",
    "\n",
    "# 이미 정의된 6개의 뷰 (데이터 증강,각 뷰 모두 스케일링 적용)\n",
    "train_views = [\n",
    "    train_binary_mutation_view, \n",
    "    train_position_stats_view, \n",
    "    train_integrated_view,\n",
    "    expanded_train_view, \n",
    "    train_hallmark_view,\n",
    "    train_encoded_view,\n",
    "]\n",
    "\n",
    "\n",
    "# 스케일러 리스트 초기화 및 스케일링\n",
    "scalers = []\n",
    "train_sparse_views = []\n",
    "for i, view in enumerate(train_views):\n",
    "    scaler = StandardScaler()\n",
    "    view_scaled = scaler.fit_transform(view)\n",
    "    joblib.dump(scaler, f'scaler_view_{i}.joblib')  # 각 스케일러 저장\n",
    "    sparse_view = csr_matrix(view_scaled)\n",
    "    train_sparse_views.append(sparse_view)\n",
    "    scalers.append(scaler)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Train/Validation 데이터 분할\n",
    "# ---------------------------\n",
    "\n",
    "train_scaled_views_split = []\n",
    "val_scaled_views_split = []\n",
    "val_indices_list = []  # 검증 데이터의 인덱스를 저장\n",
    "\n",
    "# 데이터와 타겟\n",
    "y_train = y_train_encoded  # 인코딩된 타겟 레이블 사용\n",
    "\n",
    "# 각 뷰에 대해 train/validation 분리 (Stratified Split 적용)\n",
    "for view in train_sparse_views:\n",
    "    X_train, X_val, y_train_split, y_val_split, train_indices, val_indices = train_test_split(\n",
    "        view, y_train, range(len(view.toarray())), test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    train_scaled_views_split.append(X_train)\n",
    "    val_scaled_views_split.append(X_val)\n",
    "    val_indices_list.append(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1f4ca-67cb-4274-b007-ae9dfd0085bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "모델에 데이터를 입력하기 전에 각 뷰의 특성을 표준화합니다(StandardScaler 사용). 이는 데이터의 분포를 평균이 0, 표준 편차가 1이 되도록 조정하여, 모델 학습이 특정 특성에 지나치게 치우치지 않도록 합니다.\n",
    "대부분의 데이터가 0인 6개의 view에 대해서 csr_matrix를 사용하여 스케일링된 데이터를 희소 행렬로 변환했다. (메모리 절약)\n",
    "이후 동일한 변환을 검증 데이터 또는 테스트 데이터에 적용할 수 있도록, 각 뷰의 스케일러를 joblib을 사용해 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915521b-13b4-46ba-8813-4106a3d75681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_split), y=y_train_split)\n",
    "class_weight_dict = dict(zip(np.unique(y_train_split), class_weights))\n",
    "\n",
    "def calculate_sample_weights(y, class_weight_dict):\n",
    "    return np.array([class_weight_dict[label] for label in y])\n",
    "\n",
    "# LightGBM 다중 GPU 사용 설정 및 전체 데이터 학습\n",
    "models = []\n",
    "for i, X_train_view in enumerate(train_scaled_views_split):\n",
    "    model = lgb.LGBMClassifier(device=\"gpu\", boosting_type='gbdt', n_jobs=-1, verbosity=0)\n",
    "    sample_weights = calculate_sample_weights(y_train_split, class_weight_dict)\n",
    "    \n",
    "    # 전체 데이터 학습\n",
    "    model.fit(X_train_view, y_train_split, sample_weight=sample_weights)\n",
    "    models.append(model)\n",
    "\n",
    "# 각 뷰의 검증 데이터로 예측\n",
    "val_predictions = []\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict_proba(val_scaled_views_split[i])\n",
    "    val_predictions.append(pred)\n",
    "\n",
    "# 스태킹 (신경망 메타 모델)\n",
    "num_classes = len(np.unique(y_val_split))\n",
    "y_val_categorical = to_categorical(y_val_split, num_classes=num_classes)\n",
    "\n",
    "# 메타 모델 학습용 데이터 준비\n",
    "stacked_predictions = np.hstack([pred for pred in val_predictions])\n",
    "\n",
    "# 다중 GPU 설정 (TensorFlow)\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "\n",
    "with strategy.scope():\n",
    "    # 신경망 모델 정의\n",
    "    meta_model_nn = Sequential([\n",
    "        Input(shape=(stacked_predictions.shape[1],)),  # Input 레이어 추가\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    meta_model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 조기 종료 설정\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # 메타 모델 학습 (신경망 모델)\n",
    "    meta_model_nn.fit(stacked_predictions, y_val_categorical, epochs=50, batch_size=32,\n",
    "                      validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# 검증 데이터의 원래 레이블 복원\n",
    "y_val_original = train_subclass.iloc[val_indices_list[0]].values\n",
    "\n",
    "# 검증 데이터에 대한 최종 스태킹 예측\n",
    "stacked_val_predictions = np.hstack([model.predict_proba(val_scaled_views_split[i]) for i, model in enumerate(models)])\n",
    "final_stacking_class_predictions_nn = np.argmax(meta_model_nn.predict(stacked_val_predictions), axis=1)\n",
    "\n",
    "# 성능 평가\n",
    "final_stacking_class_predictions_original_nn = label_encoder.inverse_transform(final_stacking_class_predictions_nn)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n==== 스태킹 결과 (신경망 모델) ====\")\n",
    "print(f\"Validation Accuracy (Stacking with NN): {accuracy_score(y_val_original, final_stacking_class_predictions_original_nn)}\")\n",
    "print(\"\\nClassification Report (Stacking with NN):\")\n",
    "print(classification_report(y_val_original, final_stacking_class_predictions_original_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32803d9c-745d-42c3-bbc4-1e2e09fa34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "클래스의 비율이 불균형하여 class weight를 적용하여 가중치를 주었다.\n",
    "여러가지 머신러닝 모델을 비교해보고 성능이 가장 좋았던 lightgbm을 이용하여 view들을 각각 학습하였고 최종 신경망 모델을 이용하여 스테킹하여 결과를 종합적으로 예측하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65975a6c-f590-45d5-9c54-31f06bb9aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "==== 스태킹 결과 (신경망 모델) ====\n",
    "Validation Accuracy (Stacking with NN): 0.5318291700241741\n",
    "\n",
    "Classification Report (Stacking with NN):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         ACC       0.92      0.86      0.89        14\n",
    "        BLCA       0.67      0.19      0.30        21\n",
    "        BRCA       0.42      0.69      0.52       157\n",
    "        CESC       0.50      0.13      0.21        31\n",
    "        COAD       0.74      0.64      0.69        45\n",
    "        DLBC       1.00      0.43      0.60         7\n",
    "      GBMLGG       0.63      0.67      0.65        92\n",
    "        HNSC       0.51      0.47      0.49        45\n",
    "       KIPAN       0.59      0.70      0.64       103\n",
    "        KIRC       0.72      0.79      0.75        67\n",
    "        LAML       0.58      0.47      0.52        32\n",
    "         LGG       0.72      0.67      0.70        46\n",
    "        LIHC       0.61      0.35      0.45        31\n",
    "        LUAD       0.33      0.19      0.24        37\n",
    "        LUSC       0.75      0.33      0.46        36\n",
    "          OV       0.22      0.33      0.26        51\n",
    "        PAAD       0.00      0.00      0.00        24\n",
    "        PCPG       0.34      0.38      0.36        29\n",
    "        PRAD       0.33      0.26      0.29        53\n",
    "        SARC       0.38      0.12      0.19        40\n",
    "        SKCM       0.76      0.71      0.74        55\n",
    "        STES       0.43      0.54      0.48        76\n",
    "        TGCT       0.67      0.40      0.50        25\n",
    "        THCA       0.59      0.78      0.68        65\n",
    "        THYM       0.00      0.00      0.00        19\n",
    "        UCEC       0.74      0.70      0.72        40\n",
    "\n",
    "    accuracy                           0.53      1241\n",
    "   macro avg       0.54      0.45      0.47      1241\n",
    "weighted avg       0.53      0.53      0.51      1241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1443a9e-52cd-446b-ae77-ade822d2bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6. 테스트 데이터 예측\n",
    "# ---------------------------\n",
    "print(\"===== 테스트 데이터 예측 시작 =====\")\n",
    "\n",
    "test_views = [\n",
    "    test_binary_mutation_view, \n",
    "    test_position_stats_view, \n",
    "    test_integrated_view,\n",
    "    expanded_test_view, \n",
    "    test_hallmark_view,\n",
    "    test_encoded_view\n",
    "]\n",
    "\n",
    "# 테스트 데이터 스케일링 및 희소 행렬 변환\n",
    "test_scaled_views = []\n",
    "print(\"\\n===== 테스트 데이터 스케일링 시작 =====\")\n",
    "for i, view in enumerate(test_views):\n",
    "    scaler_path = f'scaler_view_{i}.joblib'\n",
    "    print(f\"\\n[View {i}] 스케일러 파일 로드 시도: {scaler_path}\")\n",
    "    try:\n",
    "        scaler = joblib.load(scaler_path)  # 학습 시 저장한 스케일러 로드\n",
    "        print(f\"[View {i}] 스케일러 로드 성공\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"스케일러 파일 {scaler_path}을(를) 찾을 수 없습니다.\")\n",
    "    \n",
    "    view_scaled = scaler.transform(view)  # 스케일링 (transform만 수행)\n",
    "    print(f\"[View {i}] 스케일링 완료. 스케일링된 데이터 형태: {view_scaled.shape}\")\n",
    "    \n",
    "    sparse_view = csr_matrix(view_scaled)  # 희소 행렬로 변환\n",
    "    test_scaled_views.append(sparse_view)\n",
    "    print(f\"[View {i}] 희소 행렬로 변환 완료. 형식: {type(sparse_view)}, 형태: {sparse_view.shape}\")\n",
    "print(\"===== 테스트 데이터 스케일링 완료 =====\\n\")\n",
    "\n",
    "# 기본 모델을 사용한 테스트 데이터 예측 확률 생성\n",
    "test_predictions = []\n",
    "print(\"===== 테스트 데이터 예측 확률 생성 시작 =====\")\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"\\n[Model {i}] 예측 확률 생성 중...\")\n",
    "    pred_proba = model.predict_proba(test_scaled_views[i])\n",
    "    test_predictions.append(pred_proba)\n",
    "    print(f\"[Model {i}] 예측 확률 생성 완료. 예측 확률 형태: {pred_proba.shape}\")\n",
    "print(\"===== 테스트 데이터 예측 확률 생성 완료 =====\\n\")\n",
    "\n",
    "# 예측 확률 스태킹\n",
    "print(\"===== 예측 확률 스태킹 시작 =====\")\n",
    "stacked_test_predictions = np.hstack(test_predictions)\n",
    "print(f\"스태킹된 예측 확률의 형태: {stacked_test_predictions.shape}\")\n",
    "print(\"===== 예측 확률 스태킹 완료 =====\\n\")\n",
    "\n",
    "# 메타 모델을 사용한 최종 예측\n",
    "print(\"===== 메타 모델을 사용한 최종 예측 시작 =====\")\n",
    "final_test_predictions = meta_model_lgb.predict(stacked_test_predictions)\n",
    "print(f\"최종 예측 결과의 형태: {final_test_predictions.shape}\")\n",
    "\n",
    "# 레이블 인코딩 역변환\n",
    "print(\"===== 레이블 인코딩 역변환 시작 =====\")\n",
    "try:\n",
    "    final_test_labels = label_encoder.inverse_transform(final_test_predictions)\n",
    "    print(\"레이블 인코딩 역변환 완료\")\n",
    "except ValueError as e:\n",
    "    print(\"레이블 인코딩 역변환 중 오류 발생:\", e)\n",
    "    raise\n",
    "\n",
    "# 테스트 데이터에 'subclass_predict' 열 생성 및 예측값 할당\n",
    "print(\"===== 테스트 데이터에 예측된 'subclass_predict' 열 할당 시작 =====\")\n",
    "if 'subclass_predict' in test_df.columns:\n",
    "    print(\"'subclass_predict' 열이 이미 존재합니다. 기존 열을 덮어씁니다.\")\n",
    "    test_df['subclass_predict'] = final_test_labels\n",
    "else:\n",
    "    test_df = pd.concat([\n",
    "        test_df.reset_index(drop=True),  # 인덱스 일치 보장\n",
    "        pd.Series(final_test_labels, name='subclass_predict')\n",
    "    ], axis=1)\n",
    "    print(f\"'subclass_predict' 열이 테스트 데이터에 성공적으로 추가되었습니다. 테스트 데이터 형태: {test_df.shape}\")\n",
    "print(\"===== 테스트 데이터에 예측된 'subclass_predict' 열 할당 완료 =====\\n\")\n",
    "\n",
    "# 결과 미리보기\n",
    "print(\"===== 예측된 'subclass_predict'가 포함된 테스트 데이터 미리보기 =====\")\n",
    "print(test_df[['subclass_predict']].head())\n",
    "print(\"===== 테스트 데이터 예측 미리보기 완료 =====\\n\")\n",
    "\n",
    "# 예측 결과를 CSV 파일로 저장\n",
    "output_csv = 'test_with_predictions.csv'\n",
    "test_df.to_csv(output_csv, index=False)\n",
    "print(f\"===== 예측 결과가 '{output_csv}'에 저장되었습니다 =====\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1f21f-cd7e-43fe-b9c5-77520204572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "이후 검증때와 동일한 방법으로 test데이터를 예측하고 결과를 csv파일로 저장하였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
